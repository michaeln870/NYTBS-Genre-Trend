{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trend Analysis of the New York Times Best Sellers\n",
    "\n",
    "## Table of content:  \n",
    "\n",
    "0. [Introduction](#intro)\n",
    "1. [Data collection from the NYT](#nyt_data)\n",
    "2. [Data collection from Goodreads](#goodreads_data)\n",
    "3. [Data Cleaning and preparation](#data_preparation)\n",
    "4. [Data analysis](#data_analysis)\n",
    "5. [Conclusion](#conclusion)\n",
    "\n",
    "<a class=\"anchor\" id=\"intro\"></a>\n",
    "## Introduction\n",
    "\n",
    "This project's goal is to determine if there are any identifiable trends and patterns in the books that appear in The New York Times Best Sellers list. Mainly, I'll be focusing on genre, trying to determine what are the popular genres and determine if there are any trends over time that can help us predict what will be popular next year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries needed for the project\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"nyt_data\"></a>\n",
    "## 1. Data collection from the NYT\n",
    "\n",
    "\"The New York Times Best Seller list is widely considered the preeminent list of best-selling books in the United States. It has been published weekly in The New York Times Book Review since October 12, 1931. In the 21st century, it has evolved into multiple lists, grouped by genre and format, including fiction and non-fiction, hardcover, paperback and electronic.\" (Wikipedia)\n",
    "\n",
    "In this project, we will be interested in the following list, which started in 2011 and cover the last 10 years of best sellers:\n",
    "- Combined Print & E-Book Fiction\n",
    "- Combined Print & E-Book Nonfiction\n",
    "\n",
    "### The API\n",
    "\n",
    "In order to obtain the data from the NYT, we need to extract it from their website. Luckily, The New York Times provides an easy to use [API](https://developer.nytimes.com/) that can be used to pull data from their website including the best sellers list. The only limitation of their API is a limit of 4,000 requests per day and 10 requests per minute. This means that we have to sleep 6 seconds between calls to avoid hitting the per minute rate limit. Considering that we want to pull 10 years of weekly data from two lists, this equates to 1040 calls taking 6 seconds each. The total time to collect the data will therefore be roughly 2 hours.\n",
    "\n",
    "### The data\n",
    "\n",
    "The data that we will be collecting was published from 2011-02-13 to 2021-05-23. For the first 6 years, until 2017-01-29, the list consisted of 20 books per week, but was reduced to 15 books in the following editions. The list also accounts for data collected 15 days prior to the list being published. \n",
    "\n",
    "The data itself comes with the following information:\n",
    "- **rank** - The current ranking of the book\n",
    "- **rank last week** - What rank it was the previous week\n",
    "- **weeks on list** - How many weeks it appeared on the list\n",
    "- **primary_isbn10** - The main ISBN10\n",
    "- **primary_isbn10** - The main ISBN13\n",
    "- **publisher** - The name of the publisher\n",
    "- **description** - Brief description of the book\n",
    "- **title** - The title\n",
    "- **author** - The auhtor\n",
    "- **bestsellers date** - When the data was collected\n",
    "- **published date** - When the list was published\n",
    "\n",
    "A few more information appear on the data obtained from the NYT, such as a \"dagger\" columns that marks if an entry has made the list in suspicious ways such as bulk purchases. However, for this project we will not worry about this and consider everything on the list.\n",
    "\n",
    "[<img src=\"images/poweredby_nytimes_150c.PNG\">](https://developer.nytimes.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to find the encoded name of the lists that we are interested in so we can requests them with the API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_key = \"*****************\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>list_name</th>\n",
       "      <th>display_name</th>\n",
       "      <th>list_name_encoded</th>\n",
       "      <th>oldest_published_date</th>\n",
       "      <th>newest_published_date</th>\n",
       "      <th>updated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Combined Print and E-Book Fiction</td>\n",
       "      <td>Combined Print &amp; E-Book Fiction</td>\n",
       "      <td>combined-print-and-e-book-fiction</td>\n",
       "      <td>2011-02-13</td>\n",
       "      <td>2021-05-23</td>\n",
       "      <td>WEEKLY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Combined Print and E-Book Nonfiction</td>\n",
       "      <td>Combined Print &amp; E-Book Nonfiction</td>\n",
       "      <td>combined-print-and-e-book-nonfiction</td>\n",
       "      <td>2011-02-13</td>\n",
       "      <td>2021-05-23</td>\n",
       "      <td>WEEKLY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hardcover Fiction</td>\n",
       "      <td>Hardcover Fiction</td>\n",
       "      <td>hardcover-fiction</td>\n",
       "      <td>2008-06-08</td>\n",
       "      <td>2021-05-23</td>\n",
       "      <td>WEEKLY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hardcover Nonfiction</td>\n",
       "      <td>Hardcover Nonfiction</td>\n",
       "      <td>hardcover-nonfiction</td>\n",
       "      <td>2008-06-08</td>\n",
       "      <td>2021-05-23</td>\n",
       "      <td>WEEKLY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trade Fiction Paperback</td>\n",
       "      <td>Paperback Trade Fiction</td>\n",
       "      <td>trade-fiction-paperback</td>\n",
       "      <td>2008-06-08</td>\n",
       "      <td>2021-05-23</td>\n",
       "      <td>WEEKLY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              list_name                        display_name  \\\n",
       "0     Combined Print and E-Book Fiction     Combined Print & E-Book Fiction   \n",
       "1  Combined Print and E-Book Nonfiction  Combined Print & E-Book Nonfiction   \n",
       "2                     Hardcover Fiction                   Hardcover Fiction   \n",
       "3                  Hardcover Nonfiction                Hardcover Nonfiction   \n",
       "4               Trade Fiction Paperback             Paperback Trade Fiction   \n",
       "\n",
       "                      list_name_encoded oldest_published_date  \\\n",
       "0     combined-print-and-e-book-fiction            2011-02-13   \n",
       "1  combined-print-and-e-book-nonfiction            2011-02-13   \n",
       "2                     hardcover-fiction            2008-06-08   \n",
       "3                  hardcover-nonfiction            2008-06-08   \n",
       "4               trade-fiction-paperback            2008-06-08   \n",
       "\n",
       "  newest_published_date updated  \n",
       "0            2021-05-23  WEEKLY  \n",
       "1            2021-05-23  WEEKLY  \n",
       "2            2021-05-23  WEEKLY  \n",
       "3            2021-05-23  WEEKLY  \n",
       "4            2021-05-23  WEEKLY  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://api.nytimes.com/svc/books/v3/lists/names.json?api-key={}\".format(my_key)\n",
    "r = requests.get(url).json()\n",
    "nyt_lists = pd.DataFrame.from_dict(r['results'])\n",
    "nyt_lists.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the encoded names of the list that we are interested in are:\n",
    "- combined-print-and-e-book-fiction\n",
    "- combined-print-and-e-book-nonfiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_name = \"combined-print-and-e-book-fiction\"\n",
    "list_name = \"combined-print-and-e-book-nonfiction\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see that they span from 2011-02-12 to 2021-05-23. Considering that we are interested in the weekly lists, published every 7 days, we need to create a list with all the dates of when the lists were published."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.date(2011, 2, 13)\n",
    "end_date = datetime.date(2021,5,23)\n",
    "\n",
    "dates = []\n",
    "dates.append(start_date)\n",
    "\n",
    "while dates[-1] < end_date:\n",
    "    dates.append(dates[-1] + datetime.timedelta(days=7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the following code we can then requests the whole history of the lists. To duplicate the code with both fiction and nonfiction, we can simply change the list name above and rerun the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining the lists of best sellers\n",
    "url = \"https://api.nytimes.com/svc/books/v3/lists/{date}/{name}.json?api-key={key}\"\n",
    "weekly_bestsellers = pd.DataFrame()\n",
    "\n",
    "for i in range(len(dates)):\n",
    "    r = requests.get(url.format(date=dates[i], name=list_name, key=my_key))\n",
    "    if r.status_code != 200:\n",
    "        print(\"ERROR {} at {}\".format(r.status_code, dates[i]))\n",
    "        continue\n",
    "    \n",
    "    # Getting the list for that week\n",
    "    results = r.json()['results']\n",
    "    df = pd.DataFrame.from_dict(results['books'])\n",
    "\n",
    "    # Appending the weekly bestsellers and published date to the list, then combining the lists together\n",
    "    df['bestsellers_date'], df['published_date'] = [results['bestsellers_date'], dates[i]]\n",
    "    weekly_bestsellers = pd.concat([weekly_bestsellers, df])\n",
    "    \n",
    "    # suspend execution for 6 secs so we don't hit the limit per minute rate\n",
    "    time.sleep(6)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_bestsellers.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping unecessary columns\n",
    "weekly_bestsellers.drop(['asterisk', 'dagger', 'price','contributor', 'contributor_note', 'book_image',\n",
    "                         'book_image_width', 'book_image_height', 'amazon_product_url', 'age_group',\n",
    "                         'book_review_link', 'first_chapter_link', 'sunday_review_link',\n",
    "                         'article_chapter_link', 'isbns', 'buy_links', 'book_uri'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to csv\n",
    "weekly_bestsellers.to_csv(\"data/{}.csv\".format(list_name), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"goodreads_data\"></a>\n",
    "## 2. Data collection from Goodreads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we are intesrested in is the books' genre, but the New York Times doesn't provide us with more details than \"Fiction\" and \"Nonfiction\". To obtain the genre, we will use Goodreads, the most popular english platform for books, where users can vote for the genre which corresponds books they've read. Unfortunately, Goodreads doesn't provide new users with an API anymore so to obtain the genre we will have to scrape it from their website.\n",
    "\n",
    "The quick way to scrape Goodreads is to input the book's ISBN into their search engine, which will then give us the main page for the book. With the main page, we can then scrape the genre. However, the data provided by the NYT is inaccurate and incomplete. There are a few hundred missing ISBNs where for some of them they have used their internal id number, while others are not recognized by Goodreads and some don't even have an ISBN (most often because they were self published on amazon). Therefore, there's a lot of cleaning work to do.\n",
    "\n",
    "We can deal with faulty isbns by trying to retrieve it from other sources like Google Books, or simply search the name and author into Goodreads instead of the ISBN, or even simply imputing the values manually. All these solutions don't all work perfectly, or are too tedious, and require a lengthly verification process to make sure that we get the right Goodreads page for the book. I used a mix of these methods to fill in the missing or wrong data. I didn't show all of these methods below because they require a lot of manual verification, but I was eventually able to obtain the genres for the full list.\n",
    "\n",
    "The code below will get the genre from Goodreads by using the ISBN of the book. I used Beautiful Soup, but it is not the best option. It easy to use, but very slow since every requests need to be redirected to the book's page. Using a spider like Scrapy should be significantly faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to extract the genre\n",
    "def get_genre(soup):\n",
    "    tags = soup.find_all(lambda tag: tag.name == 'div' and \n",
    "                                 tag.get('class') == ['left'])\n",
    "    # Extracting the genre\n",
    "    genres = []\n",
    "    for tag in tags:\n",
    "        genre = tag.find_all(\"a\", {\"class\": \"actionLinkLite bookPageGenreLink\"})\n",
    "        if len(genre) > 1:\n",
    "            genres.append(genre[-1].getText())\n",
    "        else:\n",
    "            genres.append(genre[0].getText())\n",
    "    \n",
    "    # Extracting user votes\n",
    "    votes = []\n",
    "    lst = soup.find_all(\"a\", {\"class\": \"actionLinkLite greyText bookPageGenreLink\"})\n",
    "    for tags in lst:\n",
    "        votes.append(tags.getText()[:-6])\n",
    "    \n",
    "    return dict(zip(genres, votes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we preserved the number of votes from the genre list. This helps us filter down valid genres for the book. For instance, the main genre might have over a 100 votes, while the one that the bottom might only have 2. The genre with only 2 votes might not be as relevant as the ones with more votes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ISBN_list = fiction['primary_isbn13'].unique()\n",
    "ISBN_list = nonfiction['primary_isbn13'].unique()\n",
    "\n",
    "URL = \"https://www.goodreads.com/search?q={}\"\n",
    "\n",
    "for ISBN in ISBN_list:\n",
    "    page = requests.get(link)\n",
    "    if page.status_code != 200:\n",
    "        print(\"ERROR {} at {}\".format(page.status_code, link))\n",
    "        continue\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    genres.update({link:get_genre(soup)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get both the list for fiction and nonfiction, we can change between the commented lines above and below, then rerun the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = pd.DataFrame(list(genres.items()))\n",
    "genres.columns = ['primary_isbn13','genres_dict']\n",
    "\n",
    "#fiction = pd.merge(fiction,genres,on='primary_isbn13', how='left')\n",
    "nonfiction = pd.merge(nonfiction,genres,on='primary_isbn13', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the work\n",
    "fiction.to_csv('data/fiction_1.csv')\n",
    "nonfiction.to_csv('data/nonfiction_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"data_preparation\"></a>\n",
    "## 3. Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiction = pd.read_csv(\"data/fiction_1.csv\",index_col=0)\n",
    "nonfiction = pd.read_csv(\"data/nonfiction_1.csv\",index_col=0)\n",
    "fiction.drop(['rank_last_week','primary_isbn10','primary_isbn13','description'], axis=1, inplace=True)\n",
    "nonfiction.drop(['rank_last_week','primary_isbn10','primary_isbn13','description'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giving each book a unique ID so we can join each tables that we will create more easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiction['id'] = fiction.groupby(['title','author']).grouper.group_info[0]\n",
    "nonfiction['id'] = nonfiction.groupby(['title','author']).grouper.group_info[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publisher Cleaning  \n",
    "Some of the publishers' name are written differently, some with 'Publishing' at the end and some without, some are written under both the sub-publisher and parent publisher. We want to fix these issues to get a better sense of popular publishers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiction['publisher'] = fiction['publisher'].str.replace(r' Press| Publishers| Publishing','')\n",
    "nonfiction['publisher'] = nonfiction['publisher'].str.replace(r' Press| Publishers| Publishing','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiction['publisher'] = fiction['publisher'].apply(lambda x: x.split('/')[0])\n",
    "nonfiction['publisher'] = nonfiction['publisher'].apply(lambda x: x.split('/')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmap = {'Little, Brown':'Little, Brown & Company',\n",
    "        'Little Brown':'Little, Brown & Company',\n",
    "        'Little, Brown and Knopf':'Little, Brown & Company',\n",
    "        'Little ,Brown':'Little, Brown & Company',\n",
    "        'Knopf':'Knopf Doubleday',\n",
    "        'HQN':'Harlequin',\n",
    "        'Harlequin Mira':'Harlequin',\n",
    "        'Harlequin HQN': 'Harlequin',\n",
    "        'Doubleday':'Knopf Doubleday',\n",
    "        'Penguin':'Penguin Group',\n",
    "        'Harper':'HarperCollins'}\n",
    "\n",
    "fiction['publisher'].replace(pmap, inplace=True)\n",
    "nonfiction['publisher'].replace(pmap, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiction.to_csv('data/fiction.csv',index=False)\n",
    "nonfiction.to_csv('data/nonfiction.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genre\n",
    "Since we extracted the genre from Goodreads in a dictonary where keys were genre and votes wer the value, we need to extract the genre and votes from the dictionary. This involves \"exploding\" the dictionary into columns, then \"melting\" it back down into rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fiction\n",
    "fiction_genres = pd.concat([fiction, fiction['genres_dict'].map(eval).apply(pd.Series)], axis=1)\n",
    "fiction_genres = fiction_genres.melt(id_vars=fiction.columns,\n",
    "                                     var_name='genre', \n",
    "                                     value_name='votes')\n",
    "fiction_genres = fiction_genres.dropna(subset=['votes']).reset_index(drop=True)\n",
    "fiction_genres['votes'] = fiction_genres['votes'].astype(str).str.replace(',','').astype(float).astype(int)\n",
    "\n",
    "#nonfiction\n",
    "nonfiction_genres = pd.concat([nonfiction, nonfiction['genres_dict'].map(eval).apply(pd.Series)], axis=1)\n",
    "nonfiction_genres = nonfiction_genres.melt(id_vars=nonfiction.columns,\n",
    "                                           var_name='genre', \n",
    "                                           value_name='votes')\n",
    "nonfiction_genres = nonfiction_genres.dropna(subset=['votes']).reset_index(drop=True)\n",
    "nonfiction_genres['votes'] = nonfiction_genres['votes'].astype(str).str.replace(',','').astype(float).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the dictionary column\n",
    "fiction_genres.drop('genres_dict', axis=1, inplace=True)\n",
    "nonfiction_genres.drop('genres_dict', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also remove a few unecessary or repetitive genre that won't help us in our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_list = ['Fiction','Nonfiction','Audiobook','Ebook','Amazon','Novels','Unfinished','Roman','Book Club',\n",
    "               'Adult','Adult Fiction','Anthologies','Collections','Mystery Thriller','Biography Memoir','Autobiography','Historical']\n",
    "fiction_genres = fiction_genres[~fiction_genres['genre'].isin(remove_list)]\n",
    "nonfiction_genres = nonfiction_genres[~nonfiction_genres['genre'].isin(remove_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also extract the most voted genre, which we can safely assume is the primary genre for most books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiction_top_genres = fiction_genres.loc[fiction_genres.groupby(['bestsellers_date','rank'])['votes'].idxmax()].reset_index(drop=True)\n",
    "nonfiction_top_genres = nonfiction_genres.loc[nonfiction_genres.groupby(['bestsellers_date','rank'])['votes'].idxmax()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving DataFrame\n",
    "fiction_genres.to_csv('data/fiction_genres.csv', index=False)\n",
    "nonfiction_genres.to_csv('data/nonfiction_genres.csv', index=False)\n",
    "\n",
    "fiction_top_genres.to_csv('data/fiction_top_genres.csv', index=False)\n",
    "nonfiction_top_genres.to_csv('data/nonfiction_top_genres.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since some authors often co-author more books than they write themselves (e.g. James Patterson), in order to portray accurately the success of an author, we need to split books with multiple author names into individual rows. For instance, for books authored by \"James Patterson and Maxine Paetro\", we want a row for \"James Patterson\" and another for \"Maxine Paetro\". Below, I create a unique dataframe for co-authored books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "#fiction\n",
    "cols = fiction.columns.difference(['author'])\n",
    "authors = fiction['author'].str.split(' and | with ')\n",
    "\n",
    "fiction_author = (fiction.loc[fiction.index.repeat(authors.str.len()), cols]\n",
    "         .assign(author=list(chain.from_iterable(authors.tolist()))))\n",
    "\n",
    "#nonfiction\n",
    "nonfiction_author = nonfiction.dropna(subset=['author'])\n",
    "cols = nonfiction_author.columns.difference(['author'])\n",
    "authors = nonfiction_author['author'].str.split(' and | with ')\n",
    "\n",
    "nonfiction_author = (nonfiction_author.loc[nonfiction_author.index.repeat(authors.str.len()), cols]\n",
    "         .assign(author=list(chain.from_iterable(authors.tolist()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiction_author.to_csv('data/fiction_author.csv', index=False)\n",
    "nonfiction_author.to_csv('data/nonfiction_author.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might also be insightful to look at the title of the book and popular words that people might latch onto more. To do so, we fist want to remove symbols and words that are of no use to us. We then want to remove stopwords like 'a', 'the', etc., that again are not useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_remove = \"\\d(th|st|rd|-)|\\d|,|&|/|>|robert b. parker's|tom clancy:|[â€™']s|:|i've|i'm|#|b\\.|_|\\(|\\)|\\.\\.\\.|\\.|we're|\\?|%\"\n",
    "\n",
    "#fiction\n",
    "fiction_title = fiction.copy()\n",
    "fiction_title['title_word'] = fiction_title['title'].str.lower().str.replace(regex_remove,'').str.split()\n",
    "fiction_title = fiction_title.explode('title_word')\n",
    "\n",
    "#nonfiction\n",
    "nonfiction_title = nonfiction.copy()\n",
    "nonfiction_title['title_word'] = nonfiction_title['title'].str.lower().str.replace(regex_remove,'').str.split()\n",
    "nonfiction_title = nonfiction_title.explode('title_word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\micha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiction_title = fiction_title[~fiction_title['title_word'].isin(stop_words)]\n",
    "nonfiction_title = nonfiction_title[~nonfiction_title['title_word'].isin(stop_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiction_title.to_csv('data/fiction_title.csv')\n",
    "nonfiction_title.to_csv('data/nonfiction_title.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"data_analysis\"></a>\n",
    "## 4. Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Brief Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the analysis we can calculate a few summary statistics for publishers, authors, genres and words, however we are more interested in genre trends. To avoid cluttering the notebook with unecessary statistics, I decided to remove them. But kept a few regarding the genre that will help us understand the trends:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Romance                 1274\n",
       "Mystery                 1220\n",
       "Contemporary            1174\n",
       "Suspense                1042\n",
       "Thriller                1026\n",
       "Crime                    794\n",
       "Contemporary Romance     607\n",
       "Chick Lit                553\n",
       "Fantasy                  471\n",
       "Historical Fiction       388\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fiction_genres[fiction_genres['weeks_on_list'] == 1]['genre'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Biography           1042\n",
       "History              902\n",
       "Memoir               782\n",
       "Politics             629\n",
       "American History     339\n",
       "Science              219\n",
       "Humor                211\n",
       "Business             180\n",
       "War                  172\n",
       "Psychology           153\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonfiction_genres[nonfiction_genres['weeks_on_list'] == 1]['genre'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lists above show summary statistics for all related genres to each book on the list that appear once. This is a good way to see the general popularity of genres, but doesn't give us accurate information because a book can be categorized into different genres. For instance a book about Benjamin Franklin might be categorized under both biography and history, but the main genre is biography.\n",
    "\n",
    "Below is a bit more specific to main genres of the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mystery               691\n",
       "Romance               684\n",
       "Thriller              207\n",
       "Historical Fiction    172\n",
       "Fantasy               106\n",
       "Paranormal             98\n",
       "Chick Lit              60\n",
       "Contemporary           58\n",
       "Urban Fantasy          47\n",
       "Science Fiction        42\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fiction_top_genres[fiction_top_genres['weeks_on_list'] == 1]['genre'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "History       284\n",
       "Politics      275\n",
       "Memoir        268\n",
       "Biography     177\n",
       "Science        69\n",
       "Humor          48\n",
       "Sports         45\n",
       "Business       43\n",
       "True Crime     38\n",
       "Music          37\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonfiction_top_genres[nonfiction_top_genres['weeks_on_list'] == 1]['genre'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trend analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trend analysis can be done in Python, but it isn't the most efficient way to analyse this type of data for the analysis we are doing. An easier and more practical way is to look at the data into Tabeau. Here's the graphs produced: \n",
    "\n",
    "*Click the image to redirect to Tableau Public*\n",
    "\n",
    "[<img src=\"images/fiction_nonfiction.PNG\">](https://public.tableau.com/app/profile/michael2724/viz/NYTBestSellersGenreTrends/NYTBestSellersTrendsofPopularGenresTop5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fiction**  \n",
    "\n",
    "Looking at the plot for fiction, we can see that both mystery and romance are the most popular genres as we observed previously, however they are slowly declining in popularity in favor of alternative genres. Most significantly though is the sharp decline in romance, which seems to be overtaken by contemporary, historical fiction and thriller. Moreover we can see that historical fiction is the genre most on the rise and seem like it might eventually overtake mystery as the most popular genre\n",
    "\n",
    "**Nonfiction**\n",
    "\n",
    "Looking at the plot for fiction, we can see a significant increase in popularity for memoirs and politics, while the others seem to be slowly declining. One important thing to note about politics however is that the rise in populary seems to coincide with the election of Donald Trump, which brought a lot more interest in politics than before. This rise in popularity seems also to be declining in the last two years, which might suggest that it would go back to closer numbers than it was before 2016.\n",
    "\n",
    "Also we should note that while history seems to be declining, it is actually growing in popularity. Books purely classified as history are not growing, but books with a historical theme are, they are only categorized under a parent category such as biography or sports for instance. Looking at the graph of all the genres classifying each books appearing on the list, we can see that history books are growing in popularity.\n",
    "\n",
    "<img src=\"images/Nonfiction Genres.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"conclusion\"></a>\n",
    "## 5. Conclusion\n",
    "\n",
    "To keep the conlcusion short, we have observed a significance in the following trends:  \n",
    "- Romance is declining in popularity\n",
    "- Memoirs are increasing in popularity\n",
    "- History is increasing in popularity, for both for fiction and nonfiction\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
